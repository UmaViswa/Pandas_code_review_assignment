{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization constant__\n",
    "\n",
    "\n",
    "The concept of a normalizing constant arises in probability theory and a variety of other areas of mathematics. The normalizing constant is used to reduce any probability function to a probability density function with total probability of one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Covariance__<br>\n",
    "\n",
    "The covariance of two variables (x and y) can be represented as cov(x,y). If E[x] is the expected value or mean of a sample ‘x’, then cov(x,y) can be represented in the following way:<br><br>\n",
    "\n",
    "$$ Cov(x,y) =  \\sum_{i=0}^n \\frac {({x_{i}- \\bar{x}})({y_{j}- \\bar{y}})}{n}$$<br><br>\n",
    "\n",
    "If we look at a single variable, say ‘x’, cov(x,x), the expression can be written in the following way:<br>\n",
    "\n",
    "$$ Cov(x,x) =  \\sum_{i=0}^n \\frac {({x_{i}- \\bar{x}})({x_{j}- \\bar{x}})}{n}$$\n",
    "\n",
    "For a sample covariance, the formula is slightly adjusted:\n",
    "\n",
    "   $$ Cov(x,y) =  \\sum_{i=0}^n \\frac {({x_{i}- \\bar{x}})({y_{j}- \\bar{y}})}{n - 1}$$<br>\n",
    "\n",
    "   where: ${x_{i}}$ = the values of the x-variable <br>\n",
    "\n",
    "${y_{i}}$ = the values of the y-variable <br>\n",
    "\n",
    "$\\bar{x}$ = the mean (average) of the x-variable <br>\n",
    "\n",
    "$\\bar{y}$ = the mean (average) of the y-variable <br>\n",
    "\n",
    "n = the number of the data points<br>\n",
    "\n",
    "n - 1 = degree of freedom<br><br>Degrees of freedom is the number of independent data points that went into calculating the estimate. As we see in the example above, it is not necessarily equal to the number of items in the sample (n).<br>Covariance is used to analyze the linear relationship between the two variable.The positive and negative value in covariance matrix denotes the increasing and decreasing relationship between the two variables.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain what degrees of freedom are, let us just take an example. In a set of 3 numbers with the mean as 10 and two out of three variables as 5 and 15, there is only one possibility of the value that the third number can take up i.e. 10. With any set of 3 numbers with the same mean, for example: 12,8 and 10 or say 9,10 and 11, there is only one value for any 2 given values in the set. You can basically change the two values here and the third value fixes itself. The degree of freedom here is 2. Essentially, degrees of freedom is the number of independent data points that went into calculating the estimate. As we see in the example above, it is not necessarily equal to the number of items in the sample (n).\n",
    "\n",
    "The  diagonal of a covariance matrix provides the variance of each individual variable, covariance itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variance__<br>\n",
    "\n",
    "Variance (σ2) is a measurement of the spread between numbers in a data set. It measures how far each number in the set is from the mean and is calculated by taking the differences between each number in the set and the mean, squaring the differences (to make them positive) and dividing the sum of the squares by the number of values in the set.Variance measures the variation of a single random variable.<br><br>\n",
    "\n",
    "$$\\sigma^2 = \\sum_{i=0}^n \\frac{({x_{i}- \\bar{x}})^2} {n} $$ <br>\n",
    "\n",
    "where ${x_{i}} =  i^{th}$ data point<br>\n",
    "\n",
    "${\\bar {x}}$ = mean of all data point<br>\n",
    "\n",
    "n = the number of data points<br><br>\n",
    "A variance value of zero indicates that all values within a set of numbers are identical; all variances that are non-zero will be positive numbers. A large variance indicates that numbers in the set are far from the mean and each other, while a small variance indicates the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bias of an Estimator:__\n",
    "\n",
    "\n",
    "The bias (or bias function) of an estimator is the difference between this estimator's expected value and the true value of the parameter being estimated. \n",
    "An estimator or decision rule with zero bias is called unbiased. Otherwise the estimator is said to be biased. In statistics, \"bias\" is an objective property of an estimator, and while not a desired property.\n",
    "\n",
    "Bias can also be measured with respect to the median, rather than the mean (expected value), in which case one distinguishes median-unbiased from the usual mean-unbiasedness property. Bias is related to consistency in that consistent estimators are convergent and asymptotically unbiased (hence converge to the correct value as the number of data points grows arbitrarily large), though individual estimators in a consistent sequence may be biased (so long as the bias converges to zero); see bias versus consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Properties of Covariance Matrix__\n",
    "\n",
    "\n",
    "The covariance matrix of a random vector$X∈Rn$ with mean vectormxisdefined via:\n",
    "$$Cx=E[(X−m)(X−m)T]$$\n",
    "The (i, j)thelement of this covariance matrixCxis given by\n",
    "$$Cij=E[(Xi−mi)(Xj−mj)] =σij$$\n",
    "The diagonal entries of this covariance matrixCxare the variances of the components of the random vectorX, $$Cii=E[(Xi−mi)2] =σ2i$$\n",
    "Since the diagonal entries are all positive the trace of this covariance matrix ispositive, \n",
    "$$Trace(Cx) =n∑i=1Cii>0$$\n",
    "This covariance matrixCxis symmetric,\n",
    "$$Cx=CTxbecause :Cij=σij=σji=Cji$$\n",
    "The covariance matrixCxis positive semidefinite,\n",
    "for $a∈Rn:E{[(X−m)Ta]2}=E{[(X−m)Ta]T[(X−m)Ta]}≥0E[aT(X−m)(X−m)Ta]≥0,a∈RnaTCxa≥0,a∈Rn$\n",
    "Since the covariance matrixCxis symmetric, i.e., self-adjoint with the usualinner product its eigenvalues are all real and positive and the eigenvectors thatbelong to distinct eigenvalues are orthogonal,\n",
    "$$Cx=VΛVT=n∑i=1λi~vi~vTi$$\n",
    "As a consequence, the determinant of the covariance matrix is positive,\n",
    "$$Det(CX) =n∏i=1λi≥0$$\n",
    "The eigenvectors of the covariance matrix transform the random vector intostatistically uncorrelated random variables, i.e., into a random vector with adiagonal covariance matrix. \n",
    "The Rayleigh coefficient of the covariance matrixis bounded above and below by the maximum and minimum eigenvalue $$λmin≤aTCxaaTa,a∈R≤λmax.1$$\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
